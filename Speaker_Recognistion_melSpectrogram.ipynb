{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f8623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    from spela.spectrogram import Spectrogram \n",
    "    from spela.melspectrogram import Melspectrogram\n",
    "except:\n",
    "    !pip install spela\n",
    "    from spela.spectrogram import Spectrogram \n",
    "    from spela.melspectrogram import Melspectrogram\n",
    "    \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "data_dir = r\"C:/Users/ASUS/OneDrive - BUET/Desktop/SR_DSP/TestData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c8ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wav paths\n",
    "def get_wav_paths(speaker):\n",
    "    speaker_path = data_dir + speaker\n",
    "    all_paths = [item for item in os.listdir(speaker_path)]\n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c101197",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_16_path = get_wav_paths(\"/ID_16\")\n",
    "id_19_path = get_wav_paths(\"/ID_19\")\n",
    "id_20_path = get_wav_paths(\"/ID_20\")\n",
    "id_21_path = get_wav_paths(\"/ID_21\")\n",
    "id_29_path = get_wav_paths(\"/ID_29\")\n",
    "id_32_path = get_wav_paths(\"/ID_32\")\n",
    "id_33_path = get_wav_paths(\"/ID_33\")\n",
    "id_35_path = get_wav_paths(\"/ID_35\")\n",
    "id_41_path = get_wav_paths(\"/ID_41\")\n",
    "id_45_path = get_wav_paths(\"/ID_45\")\n",
    "id_46_path = get_wav_paths(\"/ID_46\")\n",
    "id_49_path = get_wav_paths(\"/ID_49\")\n",
    "id_53_path = get_wav_paths(\"/ID_53\")\n",
    "id_56_path = get_wav_paths(\"/ID_56\")\n",
    "id_57_path = get_wav_paths(\"/ID_57\")\n",
    "id_59_path = get_wav_paths(\"/ID_59\")\n",
    "id_64_path = get_wav_paths(\"/ID_64\")\n",
    "id_01_path = get_wav_paths(\"/ID_01\")\n",
    "id_02_path = get_wav_paths(\"/ID_02\")\n",
    "id_04_path = get_wav_paths(\"/ID_04\")\n",
    "id_05_path = get_wav_paths(\"/ID_05\")\n",
    "id_06_path = get_wav_paths(\"/ID_06\")\n",
    "id_07_path = get_wav_paths(\"/ID_07\")\n",
    "id_10_path = get_wav_paths(\"/ID_10\")\n",
    "id_11_path = get_wav_paths(\"/ID_11\")\n",
    "id_12_path = get_wav_paths(\"/ID_12\")\n",
    "id_13_path = get_wav_paths(\"/ID_13\")\n",
    "id_25_path = get_wav_paths(\"/ID_25\")\n",
    "id_26_path = get_wav_paths(\"/ID_26\")\n",
    "id_36_path = get_wav_paths(\"/ID_36\")\n",
    "id_39_path = get_wav_paths(\"/ID_39\")\n",
    "id_42_path = get_wav_paths(\"/ID_42\")\n",
    "id_43_path = get_wav_paths(\"/ID_43\")\n",
    "id_44_path = get_wav_paths(\"/ID_44\")\n",
    "id_48_path = get_wav_paths(\"/ID_48\")\n",
    "id_61_path = get_wav_paths(\"/ID_61\")\n",
    "id_62_path = get_wav_paths(\"/ID_62\")\n",
    "id_63_path = get_wav_paths(\"/ID_63\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c530a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "def load_wav(wav_path, speaker):\n",
    "    with tf.compat.v1.Session(graph=tf.compat.v1.Graph()) as sess:\n",
    "        wav_path = data_dir +speaker + \"/\"+ wav_path\n",
    "        wav_filename_placeholder = tf.compat.v1.placeholder(tf.compat.v1.string, [])\n",
    "        wav_loader = tf.io.read_file(wav_filename_placeholder)\n",
    "        wav_decoder = tf.audio.decode_wav(wav_loader, desired_channels=1)\n",
    "        wav_data = sess.run(\n",
    "            wav_decoder, feed_dict={\n",
    "                wav_filename_placeholder: wav_path\n",
    "            }).audio.flatten().reshape((1, 44100))\n",
    "        sess.close()\n",
    "    return wav_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b7a57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data\n",
    "def generate_training_data(speaker_paths, speaker, label):\n",
    "    wavs, labels = [], []\n",
    "    for i in tqdm(speaker_paths):\n",
    "        wav = load_wav(i, speaker)\n",
    "        wavs.append(wav)\n",
    "        labels.append(label)\n",
    "    return wavs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c81ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 29.53it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 319.26it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.23it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 159.99it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 225.33it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.23it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 159.72it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 132.43it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.03it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 159.69it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 226.21it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 320.08it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.04it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 159.89it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 319.97it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.04it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.03it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 132.39it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 159.82it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.25it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 225.05it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.02it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.04it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 132.44it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.00it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.05it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 320.06it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 132.39it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.04it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.02it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 225.92it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 159.97it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.04it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.04it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 319.19it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.04it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 160.03it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 226.28it/s]\n"
     ]
    }
   ],
   "source": [
    "id_32_wavs, id_32_labels = generate_training_data(id_32_path, \"/ID_32\",0) \n",
    "id_33_wavs, id_33_labels = generate_training_data(id_33_path, \"/ID_33\",1) \n",
    "id_35_wavs, id_35_labels = generate_training_data(id_35_path, \"/ID_35\",2)\n",
    "id_41_wavs, id_41_labels = generate_training_data(id_41_path, \"/ID_41\",3)\n",
    "id_45_wavs, id_45_labels = generate_training_data(id_45_path, \"/ID_45\",4)\n",
    "id_16_wavs, id_16_labels = generate_training_data(id_16_path, \"/ID_16\",5)\n",
    "id_19_wavs, id_19_labels = generate_training_data(id_19_path, \"/ID_19\",6)\n",
    "id_20_wavs, id_20_labels = generate_training_data(id_20_path, \"/ID_20\",7)\n",
    "id_21_wavs, id_21_labels = generate_training_data(id_21_path, \"/ID_21\",8)\n",
    "id_29_wavs, id_29_labels = generate_training_data(id_29_path, \"/ID_29\",9)\n",
    "id_46_wavs, id_46_labels = generate_training_data(id_46_path, \"/ID_46\",10)\n",
    "id_49_wavs, id_49_labels = generate_training_data(id_49_path, \"/ID_49\",11)\n",
    "id_53_wavs, id_53_labels = generate_training_data(id_53_path, \"/ID_53\",12)\n",
    "id_56_wavs, id_56_labels = generate_training_data(id_56_path, \"/ID_56\",13)\n",
    "id_57_wavs, id_57_labels = generate_training_data(id_57_path, \"/ID_57\",14)\n",
    "id_59_wavs, id_59_labels = generate_training_data(id_59_path, \"/ID_59\",15)\n",
    "id_64_wavs, id_64_labels = generate_training_data(id_64_path, \"/ID_64\",16)\n",
    "id_01_wavs, id_01_labels = generate_training_data(id_01_path, \"/ID_01\",17)\n",
    "id_02_wavs, id_02_labels = generate_training_data(id_02_path, \"/ID_02\",18)\n",
    "id_04_wavs, id_04_labels = generate_training_data(id_04_path, \"/ID_04\",19)\n",
    "id_05_wavs, id_05_labels = generate_training_data(id_05_path, \"/ID_05\",20)\n",
    "id_06_wavs, id_06_labels = generate_training_data(id_06_path, \"/ID_06\",21)\n",
    "id_07_wavs, id_07_labels = generate_training_data(id_07_path, \"/ID_07\",22)\n",
    "id_10_wavs, id_10_labels = generate_training_data(id_10_path, \"/ID_10\",23)\n",
    "id_11_wavs, id_11_labels = generate_training_data(id_11_path, \"/ID_11\",24)\n",
    "id_12_wavs, id_12_labels = generate_training_data(id_12_path, \"/ID_12\",25)\n",
    "id_13_wavs, id_13_labels = generate_training_data(id_13_path, \"/ID_13\",26)\n",
    "id_25_wavs, id_25_labels = generate_training_data(id_25_path, \"/ID_25\",27)\n",
    "id_26_wavs, id_26_labels = generate_training_data(id_26_path, \"/ID_26\",28)\n",
    "id_36_wavs, id_36_labels = generate_training_data(id_36_path, \"/ID_36\",29)\n",
    "id_39_wavs, id_39_labels = generate_training_data(id_39_path, \"/ID_39\",30)\n",
    "id_42_wavs, id_42_labels = generate_training_data(id_42_path, \"/ID_42\",31)\n",
    "id_43_wavs, id_43_labels = generate_training_data(id_43_path, \"/ID_43\",32)\n",
    "id_44_wavs, id_44_labels = generate_training_data(id_44_path, \"/ID_44\",33)\n",
    "id_48_wavs, id_48_labels = generate_training_data(id_48_path, \"/ID_48\",34)\n",
    "id_61_wavs, id_61_labels = generate_training_data(id_61_path, \"/ID_61\",35)\n",
    "id_62_wavs, id_62_labels = generate_training_data(id_62_path, \"/ID_62\",36)\n",
    "id_63_wavs, id_63_labels = generate_training_data(id_63_path, \"/ID_63\",37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17692616",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wavs = id_32_wavs + id_33_wavs + id_35_wavs + id_41_wavs + id_45_wavs + id_16_wavs + id_19_wavs + id_20_wavs + id_21_wavs + id_29_wavs + id_46_wavs + id_49_wavs + id_53_wavs + id_56_wavs + id_57_wavs + id_59_wavs + id_64_wavs + id_01_wavs + id_02_wavs + id_04_wavs + id_05_wavs  + id_06_wavs + id_07_wavs + id_10_wavs+ id_11_wavs+ id_12_wavs+ id_13_wavs+ id_25_wavs+ id_26_wavs + id_36_wavs + id_39_wavs + id_42_wavs + id_43_wavs + id_44_wavs + id_48_wavs + id_61_wavs + id_62_wavs + id_63_wavs\n",
    "\n",
    "all_labels = id_32_labels + id_33_labels + id_35_labels + id_41_labels  + id_45_labels + id_16_labels + id_19_labels + id_20_labels + id_21_labels + id_29_labels + id_46_labels + id_49_labels + id_53_labels + id_56_labels + id_57_labels + id_59_labels + id_64_labels + id_01_labels + id_02_labels + id_04_labels + id_05_labels + id_06_labels + id_07_labels + id_10_labels + id_11_labels + id_12_labels + id_13_labels + id_25_labels + id_26_labels + id_36_labels + id_39_labels + id_42_labels + id_43_labels + id_44_labels + id_48_labels + id_61_labels + id_62_labels + id_63_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b49c1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [\"Ayan_32\",\"Razon_33\",\"Abir_35\",\"Indronil_41\",\"Sourav_45\",\"Ananna_16\",\"Redwan_19\",\"Shafin_20\",\"Shovon_21\",\"Samdani_29\",\"Rasel_46\",\"Humayom_49\",\"Saleh_53\",\"Shihab_56\",\"Prithu_57\",\"Fatin_59\",\"Sadat_64\",\"Mrinmoy_01\",\"Elin_02\",\"Aroni_04\",\"Nabila_05\",\"Subah_06\",\"Rafi_07\",\"Plabon_07\",\"Saleah_11\",\"Sabbir_12\",\"Toiyob_13\",\"Tauhid_25\",\"Murad_26\",\"Tonmoy_36\",\"Tajwar_39\",\"Monirul_42\",\"Fariza_43\",\"Shuvro_44\",\"Tanvir_48\",\"Swadesh_61\",\"Imtiaz_62\",\"Tamim_63\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef375ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into trainin and testing set\\\n",
    "train_wavs, test_wavs, train_labels, test_labels = train_test_split(all_wavs, all_labels, test_size=0.2)\n",
    "train_x, train_y = np.array(train_wavs), np.array(train_labels)\n",
    "test_x, test_y = np.array(test_wavs), np.array(test_labels)\n",
    "\n",
    "train_y = tf.keras.utils.to_categorical(train_y)\n",
    "test_y = tf.keras.utils.to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6ebed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "def create_model(speech_feature):\n",
    "    model = tf.keras.Sequential()\n",
    "    if speech_feature == \"spectrogram\":\n",
    "        model.add(Spectrogram(n_dft=1024, n_hop=256, input_shape=(1, 44100),\n",
    "                            return_decibel_spectrogram=True, power_spectrogram=2.0,\n",
    "                            trainable_kernel=False, name='static_stft'))\n",
    "    elif speech_feature == \"melspectrogram\":\n",
    "        model.add(Melspectrogram(sr=44100, n_mels=128,n_dft=1024, n_hop=256,\n",
    "                            input_shape=(1 , 44100),return_decibel_melgram=True,\n",
    "                            trainable_kernel=False, name='melgram'))\n",
    "   \n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(38, activation=\"softmax\"))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate =3e-4)\n",
    "            , loss = \"categorical_crossentropy\"\n",
    "            , metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "348fcfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "melgram (Melspectrogram)     (None, 128, 173, 1)       1116288   \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 126, 171, 64)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 342720)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 38)                13023398  \n",
      "=================================================================\n",
      "Total params: 14,140,326\n",
      "Trainable params: 14,140,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# melspectrogram model\n",
    "model = create_model(\"melspectrogram\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63053f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 152 samples, validate on 38 samples\n",
      "Epoch 1/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 566.3224 - accuracy: 0.0197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 28ms/sample - loss: 566.3224 - accuracy: 0.0197 - val_loss: 970.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 4s 28ms/sample - loss: 939.6414 - accuracy: 0.0263 - val_loss: 1054.8830 - val_accuracy: 0.0789\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 4s 25ms/sample - loss: 1127.4807 - accuracy: 0.0987 - val_loss: 1290.6979 - val_accuracy: 0.0263\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 4s 25ms/sample - loss: 1289.0905 - accuracy: 0.0789 - val_loss: 1302.5118 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 4s 24ms/sample - loss: 1183.9448 - accuracy: 0.1118 - val_loss: 865.2719 - val_accuracy: 0.0789\n",
      "Epoch 6/50\n",
      " 32/152 [=====>........................] - ETA: 2s - loss: 676.5802 - accuracy: 0.1875"
     ]
    }
   ],
   "source": [
    "# melspectrogram model\n",
    "model = create_model(\"melspectrogram\")\n",
    "model.fit(x=train_x, y=train_y, epochs=50, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87448198",
   "metadata": {},
   "outputs": [],
   "source": [
    "z,sr = librosa.load(\"C:/Users/ASUS/OneDrive - BUET/Desktop/SR_DSP/TestData/ID_59/ID_59_3.wav\",duration=1,sr=44100)\n",
    "z = np.array(z,dtype=object)\n",
    "z = z.reshape(1,44100)\n",
    "z = z[np.newaxis,:]\n",
    "y = model.predict(z)\n",
    "y = y.astype(int)\n",
    "print(y)\n",
    "idx = np.where(y == 1.0)\n",
    "print(name_list[int(idx[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4fe387",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x)\n",
    "\n",
    "\n",
    "matrix = metrics.confusion_matrix(test_y.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print(matrix)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrix)\n",
    "disp.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import time\n",
    "\n",
    "fs = 44100  # Sample rate\n",
    "seconds = 3  # Duration of recording\n",
    "print(\"Start Speaking Now\\n\")\n",
    "time.sleep(0.5)\n",
    "print('Listening....Speak Now')\n",
    "myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=1)\n",
    "sd.wait()  # Wait until recording is finished\n",
    "print(\"Done Recording\\n\")\n",
    "\n",
    "test1 = np.array(myrecording[20000:20000+44100])\n",
    "test2 = np.array(myrecording[0:44100])\n",
    "\n",
    "test1 = test1.reshape(1,44100)\n",
    "test1 = test1[np.newaxis,:]\n",
    "test2 = test2.reshape(1,44100)\n",
    "test2 = test2[np.newaxis,:]\n",
    "\n",
    "y1 = model.predict(test1)\n",
    "y1 = y1.astype(int)\n",
    "print(y1)\n",
    "y2 = model.predict(test2)\n",
    "y2 = y2.astype(int)\n",
    "print(y2)\n",
    "\n",
    "if np.sum(y1)>0:\n",
    "\n",
    "        index1 = np.where(y1 == 1)\n",
    "         \n",
    "        index1 = np.array(index1)\n",
    "        pos = index1[1][0]\n",
    "        print(name_list[pos])\n",
    "       \n",
    "elif np.sum(y2)>0:\n",
    "        index1 = np.where(y2 == 1)\n",
    "\n",
    "        index1 = np.array(index1)\n",
    "        pos = index1[1][0]\n",
    "        print(name_list[pos])\n",
    "else:\n",
    "        print(\"Input again\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b07f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
