{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f8623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    from spela.spectrogram import Spectrogram \n",
    "    from spela.melspectrogram import Melspectrogram\n",
    "except:\n",
    "    !pip install spela\n",
    "    from spela.spectrogram import Spectrogram \n",
    "    from spela.melspectrogram import Melspectrogram\n",
    "    \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "data_dir = r\"F:\\Augmentated_Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wav paths\n",
    "def get_wav_paths(speaker):\n",
    "    speaker_path = data_dir + speaker\n",
    "    all_paths = [item for item in os.listdir(speaker_path)]\n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d3334",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_list = ['ID_01','ID_03','ID_04','ID_05','ID_06','ID_07','ID_09','ÍD_10','ID_12','ID_13','ID_14','ID_15','ID_16','ID_17','ID_19','ID_20','ID_29','ID_30','ID_31','ID_32','ID_43','ID_45','ID_48','ID_50','ID_55','ID_56','ID_58','ID_64']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c101197",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_01_path = get_wav_paths(\"/ID_01\")\n",
    "id_03_path = get_wav_paths(\"/ID_03\")\n",
    "id_04_path = get_wav_paths(\"/ID_04\")\n",
    "id_05_path = get_wav_paths(\"/ID_05\")\n",
    "id_06_path = get_wav_paths(\"/ID_06\")\n",
    "id_07_path = get_wav_paths(\"/ID_07\")\n",
    "id_09_path = get_wav_paths(\"/ID_09\")\n",
    "id_10_path = get_wav_paths(\"/ID_10\")\n",
    "id_12_path = get_wav_paths(\"/ID_12\")\n",
    "id_13_path = get_wav_paths(\"/ID_13\")\n",
    "id_14_path = get_wav_paths(\"/ID_14\")\n",
    "id_15_path = get_wav_paths(\"/ID_15\")\n",
    "id_16_path = get_wav_paths(\"/ID_16\")\n",
    "id_17_path = get_wav_paths(\"/ID_17\")\n",
    "id_19_path = get_wav_paths(\"/ID_19\")\n",
    "id_20_path = get_wav_paths(\"/ID_20\")\n",
    "id_29_path = get_wav_paths(\"/ID_29\")\n",
    "id_30_path = get_wav_paths(\"/ID_30\")\n",
    "id_31_path = get_wav_paths(\"/ID_31\")\n",
    "id_32_path = get_wav_paths(\"/ID_32\")\n",
    "id_43_path = get_wav_paths(\"/ID_43\")\n",
    "id_45_path = get_wav_paths(\"/ID_45\")\n",
    "id_48_path = get_wav_paths(\"/ID_48\")\n",
    "id_50_path = get_wav_paths(\"/ID_50\")\n",
    "id_55_path = get_wav_paths(\"/ID_55\")\n",
    "id_56_path = get_wav_paths(\"/ID_56\")\n",
    "id_58_path = get_wav_paths(\"/ID_58\")\n",
    "id_64_path = get_wav_paths(\"/ID_64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c530a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "def load_wav(wav_path, speaker):\n",
    "    with tf.compat.v1.Session(graph=tf.compat.v1.Graph()) as sess:\n",
    "        wav_path = data_dir +speaker + \"/\"+ wav_path\n",
    "        wav_filename_placeholder = tf.compat.v1.placeholder(tf.compat.v1.string, [])\n",
    "        wav_loader = tf.io.read_file(wav_filename_placeholder)\n",
    "        wav_decoder = tf.audio.decode_wav(wav_loader, desired_channels=1)\n",
    "        wav_data = sess.run(\n",
    "            wav_decoder, feed_dict={\n",
    "                wav_filename_placeholder: wav_path\n",
    "            }).audio.flatten().reshape((1, 132300))\n",
    "        sess.close()\n",
    "    return wav_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data\n",
    "def generate_training_data(speaker_paths, speaker, label):\n",
    "    wavs, labels = [], []\n",
    "    count = 0\n",
    "    for i in tqdm(speaker_paths):\n",
    "        if count>19:\n",
    "            break\n",
    "        wav = load_wav(i, speaker)\n",
    "        wavs.append(wav)\n",
    "        labels.append(label)\n",
    "        count += 1\n",
    "    return wavs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c81ce9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_01_wavs, id_01_labels = generate_training_data(id_01_path, \"/ID_01\",0) \n",
    "id_03_wavs, id_03_labels = generate_training_data(id_03_path, \"/ID_03\",1) \n",
    "id_04_wavs, id_04_labels = generate_training_data(id_04_path, \"/ID_04\",2)\n",
    "id_05_wavs, id_05_labels = generate_training_data(id_05_path, \"/ID_05\",3)\n",
    "id_06_wavs, id_06_labels = generate_training_data(id_06_path, \"/ID_06\",4)\n",
    "id_07_wavs, id_07_labels = generate_training_data(id_07_path, \"/ID_07\",5)\n",
    "id_09_wavs, id_09_labels = generate_training_data(id_09_path, \"/ID_09\",6)\n",
    "id_10_wavs, id_10_labels = generate_training_data(id_10_path, \"/ID_10\",7)\n",
    "id_12_wavs, id_12_labels = generate_training_data(id_12_path, \"/ID_12\",8)\n",
    "id_13_wavs, id_13_labels = generate_training_data(id_13_path, \"/ID_13\",9)\n",
    "id_14_wavs, id_14_labels = generate_training_data(id_14_path, \"/ID_14\",10)\n",
    "id_15_wavs, id_15_labels = generate_training_data(id_15_path, \"/ID_15\",11)\n",
    "id_16_wavs, id_16_labels = generate_training_data(id_16_path, \"/ID_16\",12)\n",
    "id_17_wavs, id_17_labels = generate_training_data(id_17_path, \"/ID_17\",13)\n",
    "id_19_wavs, id_19_labels = generate_training_data(id_19_path, \"/ID_19\",14)\n",
    "id_20_wavs, id_20_labels = generate_training_data(id_20_path, \"/ID_20\",15)\n",
    "id_29_wavs, id_29_labels = generate_training_data(id_29_path, \"/ID_29\",16)\n",
    "id_30_wavs, id_30_labels = generate_training_data(id_30_path, \"/ID_30\",17)\n",
    "id_31_wavs, id_31_labels = generate_training_data(id_31_path, \"/ID_31\",18)\n",
    "id_32_wavs, id_32_labels = generate_training_data(id_32_path, \"/ID_32\",19)\n",
    "id_43_wavs, id_43_labels = generate_training_data(id_43_path, \"/ID_43\",20)\n",
    "id_45_wavs, id_45_labels = generate_training_data(id_45_path, \"/ID_45\",21)\n",
    "id_48_wavs, id_48_labels = generate_training_data(id_48_path, \"/ID_48\",22)\n",
    "id_50_wavs, id_50_labels = generate_training_data(id_50_path, \"/ID_50\",23)\n",
    "id_55_wavs, id_55_labels = generate_training_data(id_55_path, \"/ID_55\",24)\n",
    "id_56_wavs, id_56_labels = generate_training_data(id_56_path, \"/ID_56\",25)\n",
    "id_58_wavs, id_58_labels = generate_training_data(id_58_path, \"/ID_58\",26)\n",
    "id_64_wavs, id_64_labels = generate_training_data(id_64_path, \"/ID_64\",27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17692616",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wavs = id_01_wavs + id_03_wavs + id_04_wavs + id_05_wavs + id_06_wavs + id_07_wavs + id_09_wavs + id_10_wavs + id_12_wavs + id_13_wavs + id_14_wavs + id_15_wavs + id_16_wavs + id_17_wavs + id_19_wavs + id_20_wavs + id_29_wavs + id_30_wavs + id_31_wavs + id_32_wavs  + id_43_wavs + id_45_wavs + id_48_wavs+ id_50_wavs+ id_55_wavs+ id_56_wavs+ id_58_wavs+ id_64_wavs\n",
    "\n",
    "all_labels = id_01_labels + id_03_labels + id_04_labels + id_05_labels + id_06_labels + id_07_labels + id_09_labels + id_10_labels + id_12_labels + id_13_labels + id_14_labels + id_15_labels + id_16_labels + id_17_labels + id_19_labels + id_20_labels + id_29_labels  + id_30_labels + id_31_labels + id_32_labels  + id_43_labels + id_45_labels + id_48_labels+ id_50_labels+ id_55_labels+ id_56_labels+ id_58_labels+ id_64_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef375ad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the dataset into trainin and testing set\\\n",
    "train_wavs, test_wavs, train_labels, test_labels = train_test_split(all_wavs, all_labels, test_size=0.2)\n",
    "del all_wavs\n",
    "del all_labels\n",
    "train_x, train_y = np.array(train_wavs), np.array(train_labels)\n",
    "del train_wavs\n",
    "del train_labels\n",
    "print(train_x.shape)\n",
    "test_x, test_y = np.array(test_wavs), np.array(test_labels)\n",
    "del test_wavs\n",
    "del test_labels\n",
    "print(test_x.shape)\n",
    "train_y = tf.keras.utils.to_categorical(train_y)\n",
    "print(train_y.shape)\n",
    "test_y = tf.keras.utils.to_categorical(test_y)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfafb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC Feature Extraction\n",
    "\n",
    "train_x_new = []\n",
    "test_x_new = []\n",
    "INPUT_SHAPE = (517,128)\n",
    "\n",
    "train_x_new = np.zeros((train_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float32)\n",
    "\n",
    "count = 0\n",
    "for sample in train_x:\n",
    "    sample = sample.reshape(132300,)\n",
    "    train_x_new[count, :, :128] = librosa.feature.mfcc(y=sample, sr=2*44100, hop_length=256, n_fft=256, n_mfcc=128).T\n",
    "    count += 1\n",
    "    if count%400== 0:\n",
    "        print('Train', count)\n",
    "        \n",
    "test_x_new = np.zeros((test_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float32)\n",
    "\n",
    "count = 0\n",
    "for sample in test_x:\n",
    "    sample = sample.reshape(132300,)\n",
    "    test_x_new[count, :, :80] = librosa.feature.mfcc(y=sample, sr=2*44100, hop_length=256, n_fft=256, n_mfcc=128).T\n",
    "    count += 1\n",
    "    if count%100 == 0:\n",
    "        print('Test', count) \n",
    "\n",
    "del train_x\n",
    "del test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f82e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_new = np.expand_dims(train_x_new, axis=3)\n",
    "test_x_new = np.expand_dims(test_x_new, axis=3)\n",
    "print(train_x_new.shape, test_x_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ebed06",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Creating a CNN Model\n",
    "\n",
    "def create_model(speech_feature):\n",
    "    model = tf.keras.Sequential()\n",
    "    if speech_feature == \"spectrogram\":\n",
    "        model.add(Spectrogram(n_dft=1024, n_hop=256, input_shape=(1,132300),\n",
    "                            return_decibel_spectrogram=True, power_spectrogram=2.0,\n",
    "                            trainable_kernel=False, name='static_stft'))\n",
    "    elif speech_feature == \"melspectrogram\":\n",
    "        model.add(Melspectrogram(sr=44100, n_mels=128,n_dft=1024, n_hop=256,\n",
    "                            input_shape=(1 , 132300),return_decibel_melgram=True,\n",
    "                            trainable_kernel=False, name='melgram'))\n",
    "    elif speech_feature == \"mfcc\":\n",
    "        model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", input_shape=(517,128,1)))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())        \n",
    "        model.add(tf.keras.layers.Dense(28, activation=\"softmax\"))\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4)\n",
    "                , loss = \"categorical_crossentropy\"\n",
    "                , metrics = [\"accuracy\"])\n",
    "        return model\n",
    "   \n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(28, activation=\"softmax\"))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate =3e-4)\n",
    "            , loss = \"categorical_crossentropy\"\n",
    "            , metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\"mfcc\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63053f5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " #...............Training mfcc_model\n",
    "\n",
    "history = model.fit(x=train_x_new, y=train_y, epochs=2, validation_data=(test_x_new, test_y))\n",
    "\n",
    "plt.plot(history.history['accuracy'],'-go',linewidth = 4,markersize = 12)\n",
    "plt.plot(history.history['val_accuracy'],'-bo',linewidth = 4,markersize = 12)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "###summarize history for loss ###\n",
    "\n",
    "plt.plot(history.history['loss'],'-go',linewidth = 4,markersize = 12)\n",
    "plt.plot(history.history['val_loss'],'-bo',linewidth = 4,markersize = 12)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f30759",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"C:\\Users\\ASUS\\OneDrive - BUET\\Desktop\\SR_DSP\\Test Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa41715",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_01_path = get_wav_paths(\"/ID_01\")\n",
    "id_03_path = get_wav_paths(\"/ID_03\")\n",
    "id_04_path = get_wav_paths(\"/ID_04\")\n",
    "id_05_path = get_wav_paths(\"/ID_05\")\n",
    "id_06_path = get_wav_paths(\"/ID_06\")\n",
    "id_07_path = get_wav_paths(\"/ID_07\")\n",
    "id_09_path = get_wav_paths(\"/ID_09\")\n",
    "id_10_path = get_wav_paths(\"/ID_10\")\n",
    "id_12_path = get_wav_paths(\"/ID_12\")\n",
    "id_13_path = get_wav_paths(\"/ID_13\")\n",
    "id_14_path = get_wav_paths(\"/ID_14\")\n",
    "id_15_path = get_wav_paths(\"/ID_15\")\n",
    "id_16_path = get_wav_paths(\"/ID_16\")\n",
    "id_17_path = get_wav_paths(\"/ID_17\")\n",
    "id_19_path = get_wav_paths(\"/ID_19\")\n",
    "id_20_path = get_wav_paths(\"/ID_20\")\n",
    "id_29_path = get_wav_paths(\"/ID_29\")\n",
    "id_30_path = get_wav_paths(\"/ID_30\")\n",
    "id_31_path = get_wav_paths(\"/ID_31\")\n",
    "id_32_path = get_wav_paths(\"/ID_32\")\n",
    "id_43_path = get_wav_paths(\"/ID_43\")\n",
    "id_45_path = get_wav_paths(\"/ID_45\")\n",
    "id_48_path = get_wav_paths(\"/ID_48\")\n",
    "id_50_path = get_wav_paths(\"/ID_50\")\n",
    "id_55_path = get_wav_paths(\"/ID_55\")\n",
    "id_56_path = get_wav_paths(\"/ID_56\")\n",
    "id_58_path = get_wav_paths(\"/ID_58\")\n",
    "id_64_path = get_wav_paths(\"/ID_64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a233ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_01_wavs, id_01_labels = generate_training_data(id_01_path, \"/ID_01\",0) \n",
    "id_03_wavs, id_03_labels = generate_training_data(id_03_path, \"/ID_03\",1) \n",
    "id_04_wavs, id_04_labels = generate_training_data(id_04_path, \"/ID_04\",2)\n",
    "id_05_wavs, id_05_labels = generate_training_data(id_05_path, \"/ID_05\",3)\n",
    "id_06_wavs, id_06_labels = generate_training_data(id_06_path, \"/ID_06\",4)\n",
    "id_07_wavs, id_07_labels = generate_training_data(id_07_path, \"/ID_07\",5)\n",
    "id_09_wavs, id_09_labels = generate_training_data(id_09_path, \"/ID_09\",6)\n",
    "id_10_wavs, id_10_labels = generate_training_data(id_10_path, \"/ID_10\",7)\n",
    "id_12_wavs, id_12_labels = generate_training_data(id_12_path, \"/ID_12\",8)\n",
    "id_13_wavs, id_13_labels = generate_training_data(id_13_path, \"/ID_13\",9)\n",
    "id_14_wavs, id_14_labels = generate_training_data(id_14_path, \"/ID_14\",10)\n",
    "id_15_wavs, id_15_labels = generate_training_data(id_15_path, \"/ID_15\",11)\n",
    "id_16_wavs, id_16_labels = generate_training_data(id_16_path, \"/ID_16\",12)\n",
    "id_17_wavs, id_17_labels = generate_training_data(id_17_path, \"/ID_17\",13)\n",
    "id_19_wavs, id_19_labels = generate_training_data(id_19_path, \"/ID_19\",14)\n",
    "id_20_wavs, id_20_labels = generate_training_data(id_20_path, \"/ID_20\",15)\n",
    "id_29_wavs, id_29_labels = generate_training_data(id_29_path, \"/ID_29\",16)\n",
    "id_30_wavs, id_30_labels = generate_training_data(id_30_path, \"/ID_30\",17)\n",
    "id_31_wavs, id_31_labels = generate_training_data(id_31_path, \"/ID_31\",18)\n",
    "id_32_wavs, id_32_labels = generate_training_data(id_32_path, \"/ID_32\",19)\n",
    "id_43_wavs, id_43_labels = generate_training_data(id_43_path, \"/ID_43\",20)\n",
    "id_45_wavs, id_45_labels = generate_training_data(id_45_path, \"/ID_45\",21)\n",
    "id_48_wavs, id_48_labels = generate_training_data(id_48_path, \"/ID_48\",22)\n",
    "id_50_wavs, id_50_labels = generate_training_data(id_50_path, \"/ID_50\",23)\n",
    "id_55_wavs, id_55_labels = generate_training_data(id_55_path, \"/ID_55\",24)\n",
    "id_56_wavs, id_56_labels = generate_training_data(id_56_path, \"/ID_56\",25)\n",
    "id_58_wavs, id_58_labels = generate_training_data(id_58_path, \"/ID_58\",26)\n",
    "id_64_wavs, id_64_labels = generate_training_data(id_64_path, \"/ID_64\",27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1556e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wavs = id_01_wavs + id_03_wavs + id_04_wavs + id_05_wavs + id_06_wavs + id_07_wavs + id_09_wavs + id_10_wavs + id_12_wavs + id_13_wavs + id_14_wavs + id_15_wavs + id_16_wavs + id_17_wavs + id_19_wavs + id_20_wavs + id_29_wavs + id_30_wavs + id_31_wavs + id_32_wavs  + id_43_wavs + id_45_wavs + id_48_wavs+ id_50_wavs+ id_55_wavs+ id_56_wavs+ id_58_wavs+ id_64_wavs\n",
    "\n",
    "all_labels = id_01_labels + id_03_labels + id_04_labels + id_05_labels + id_06_labels + id_07_labels + id_09_labels + id_10_labels + id_12_labels + id_13_labels + id_14_labels + id_15_labels + id_16_labels + id_17_labels + id_19_labels + id_20_labels + id_29_labels  + id_30_labels + id_31_labels + id_32_labels  + id_43_labels + id_45_labels + id_48_labels+ id_50_labels+ id_55_labels+ id_56_labels+ id_58_labels+ id_64_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "###..... Test set initialization......###\n",
    "test_wavs,test_labels = all_wavs, all_labels\n",
    "test_x, test_y = np.array(test_wavs), np.array(test_labels)\n",
    "test_y = tf.keras.utils.to_categorical(test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa8f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_SHAPE = (517,128)\n",
    "       \n",
    "test_x_new = np.zeros((test_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float32)\n",
    "\n",
    "count = 0\n",
    "for sample in test_wavs:\n",
    "    sample = sample.reshape(132300,)\n",
    "    test_x_new[count, :, :128] = librosa.feature.mfcc(y=sample, sr=2*44100, hop_length=256, n_fft=256, n_mfcc=128).T\n",
    "    count += 1\n",
    "    if count%300 == 0:\n",
    "        print('Test', count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d3cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_new = np.expand_dims(test_x_new, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4fe387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x_new)\n",
    "\n",
    "matrix = metrics.confusion_matrix(test_y.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print(matrix)\n",
    "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
    "plt.imshow(matrix)\n",
    "plt.colorbar()\n",
    "ticks=np.linspace(0, 37,num=38)\n",
    "plt.xticks(ticks,fontsize=6)\n",
    "plt.yticks(ticks,fontsize=6)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72dea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(test_y.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_y.argmax(axis=1), predictions.argmax(axis=1),average='macro')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_y.argmax(axis=1), predictions.argmax(axis=1),average='macro')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(test_y.argmax(axis=1), predictions.argmax(axis=1),average='macro')\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"model_mfcc.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I am Base \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1b0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
